{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification model**"
      ],
      "metadata": {
        "id": "g1Gv3BNVaBE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습하기에 들어가기 전, 앞서 선택한 최종 변수들을 사용하여 학습/시험용 데이터를 생성하겠습니다."
      ],
      "metadata": {
        "id": "dq_0emkB3Id2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = df[['성별코드', '연령대 코드(5세단위)', '신장(5Cm단위)', '체중(5Kg 단위)', '허리둘레', \n",
        "             '시력(좌)', '시력(우)', '청력(좌)', '청력(우)', '식전혈당(공복혈당)', '혈색소', \n",
        "             '요단백', '혈청크레아티닌', '(혈청지오티)AST', '(혈청지오티)ALT', '감마 지티피', \n",
        "             '흡연상태', '음주여부', '구강검진 수검여부']]\n",
        "             \n",
        "y_data = df[['혈압상태']]"
      ],
      "metadata": {
        "id": "DIZk1Tr63GbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7:3의 비율로 학습데이터와 검증데이터를 분리합니다."
      ],
      "metadata": {
        "id": "VBZiDo-y5OWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=0, stratify = y_data)"
      ],
      "metadata": {
        "id": "CUbDLw_Q3GY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "scale이 각각 다른 연속형 변수들의 값을 통일시키기 위해 표준화 작업을 수행합니다."
      ],
      "metadata": {
        "id": "daIJGlif43bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "cols_n = ['신장(5Cm단위)', '체중(5Kg 단위)', '허리둘레', '시력(좌)', '시력(우)', \n",
        "          '청력(좌)', '청력(우)', '식전혈당(공복혈당)', '혈색소', '요단백',\n",
        "          '혈청크레아티닌', '(혈청지오티)AST', '(혈청지오티)ALT', '감마 지티피']\n",
        "scaler.fit(x_train[cols_n])\n",
        "x_train[cols_n] = scaler.transform(x_train[cols_n])\n",
        "x_test[cols_n] = scaler.transform(x_test[cols_n])"
      ],
      "metadata": {
        "id": "KGY7SXJr3GWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tensorflow와 Pytorch 기반의 심층 신경망 모델을 구축합니다. "
      ],
      "metadata": {
        "id": "IL890mHI5VYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pytorch**"
      ],
      "metadata": {
        "id": "4xMcp09jA_Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "F5IgzJq-cLlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import AdamW\n",
        "from datasets import load_metric\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "KmtDfSf3b6sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(19, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Gp4iNuB5ckwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        X_item, y_item = self.data[index]\n",
        "        return X_item, y_item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "2jHKN-90cSvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DNN()\n",
        "model"
      ],
      "metadata": {
        "id": "Y3R-tMGjd5Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a9f1371-c05d-4e0d-a8d2-04ec68f95559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNN(\n",
              "  (fc1): Linear(in_features=19, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0)\n",
        "\n",
        "train_df, val_df"
      ],
      "metadata": {
        "id": "DksNJ5IL0Iva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b05cbcf-c0f0-4e16-ef1a-e2a830bdb32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(        성별코드  연령대 코드(5세단위)  신장(5Cm단위)  체중(5Kg 단위)   허리둘레  시력(좌)  시력(우)  청력(좌)  \\\n",
              " 50211      1            11        165          55   75.1    1.2    1.2    1.0   \n",
              " 467405     1             9        170          85   91.0    1.5    1.5    1.0   \n",
              " 174239     2            10        155          55   83.3    0.7    0.7    1.0   \n",
              " 236900     2             9        155          50   78.0    1.5    1.5    1.0   \n",
              " 157759     2            14        160          65   74.0    0.8    0.4    1.0   \n",
              " ...      ...           ...        ...         ...    ...    ...    ...    ...   \n",
              " 153314     2            11        160          75   82.0    0.7    0.6    1.0   \n",
              " 970050     2            13        140          70  100.0    0.4    0.5    1.0   \n",
              " 118727     2             9        155          50   76.0    1.2    1.2    1.0   \n",
              " 438802     2            10        165          50   65.6    0.9    0.8    1.0   \n",
              " 307755     1            11        175          70   81.0    1.0    1.2    1.0   \n",
              " \n",
              "         청력(우)  식전혈당(공복혈당)   혈색소  요단백  혈청크레아티닌  (혈청지오티)AST  (혈청지오티)ALT  감마 지티피  \\\n",
              " 50211     1.0        81.0  15.8  1.0      0.8        38.0        26.0   136.0   \n",
              " 467405    1.0       100.0  16.2  1.0      1.0        23.0        48.0    43.0   \n",
              " 174239    1.0        94.0  12.8  2.0      0.7        27.0        28.0    13.0   \n",
              " 236900    1.0        89.0  13.2  1.0      0.8        19.0        11.0     4.0   \n",
              " 157759    1.0       105.0  12.9  1.0      0.7        18.0        19.0    24.0   \n",
              " ...       ...         ...   ...  ...      ...         ...         ...     ...   \n",
              " 153314    1.0       117.0  13.1  1.0      0.7        22.0        19.0    33.0   \n",
              " 970050    1.0        93.0  13.6  1.0      0.6        19.0        20.0    17.0   \n",
              " 118727    1.0       101.0   8.8  1.0      0.8        22.0        10.0    41.0   \n",
              " 438802    1.0        93.0  13.1  1.0      0.5        17.0        12.0    14.0   \n",
              " 307755    1.0       108.0  16.3  1.0      1.0        21.0        34.0    16.0   \n",
              " \n",
              "         흡연상태  음주여부  구강검진 수검여부  혈압상태  \n",
              " 50211    3.0   1.0          1     0  \n",
              " 467405   2.0   0.0          1     1  \n",
              " 174239   1.0   0.0          0     2  \n",
              " 236900   1.0   0.0          0     2  \n",
              " 157759   1.0   0.0          0     1  \n",
              " ...      ...   ...        ...   ...  \n",
              " 153314   1.0   1.0          0     0  \n",
              " 970050   1.0   0.0          0     0  \n",
              " 118727   1.0   1.0          0     2  \n",
              " 438802   1.0   1.0          0     2  \n",
              " 307755   2.0   1.0          1     2  \n",
              " \n",
              " [784106 rows x 20 columns],\n",
              "         성별코드  연령대 코드(5세단위)  신장(5Cm단위)  체중(5Kg 단위)  허리둘레  시력(좌)  시력(우)  청력(좌)  \\\n",
              " 351416     1            13        170          60  78.0    0.8    0.8    1.0   \n",
              " 918599     1            12        165          70  83.0    1.0    1.0    1.0   \n",
              " 728046     2            12        150          65  94.0    0.5    0.4    1.0   \n",
              " 300121     1            13        160          60  74.9    0.5    0.8    1.0   \n",
              " 872503     2            13        155          60  85.0    0.7    0.8    1.0   \n",
              " ...      ...           ...        ...         ...   ...    ...    ...    ...   \n",
              " 435271     1            16        165          70  92.0    0.5    0.6    1.0   \n",
              " 435997     1            13        160          55  80.0    0.3    0.3    1.0   \n",
              " 678590     1            12        170          60  85.0    0.7    1.0    1.0   \n",
              " 207290     2            11        150          45  67.0    0.8    1.0    1.0   \n",
              " 668889     1             9        165          55  72.0    0.9    0.9    1.0   \n",
              " \n",
              "         청력(우)  식전혈당(공복혈당)   혈색소  요단백  혈청크레아티닌  (혈청지오티)AST  (혈청지오티)ALT  감마 지티피  \\\n",
              " 351416    1.0       105.0  13.9  1.0      1.0        15.0        11.0    19.0   \n",
              " 918599    1.0       102.0  15.4  1.0      1.0        22.0        21.0    22.0   \n",
              " 728046    1.0       110.0  13.9  1.0      0.6        26.0        16.0    42.0   \n",
              " 300121    1.0        83.0  15.8  1.0      1.1        36.0        36.0    26.0   \n",
              " 872503    1.0       101.0  14.0  1.0      0.6        21.0        13.0     8.0   \n",
              " ...       ...         ...   ...  ...      ...         ...         ...     ...   \n",
              " 435271    1.0        96.0  16.5  1.0      1.2        25.0        12.0    39.0   \n",
              " 435997    2.0        91.0  14.8  1.0      0.9        33.0        34.0    32.0   \n",
              " 678590    1.0       103.0  13.6  1.0      0.9        55.0        91.0    40.0   \n",
              " 207290    1.0        88.0  12.6  1.0      0.8        39.0        27.0     9.0   \n",
              " 668889    1.0        85.0  14.9  1.0      0.8        33.0        18.0    22.0   \n",
              " \n",
              "         흡연상태  음주여부  구강검진 수검여부  혈압상태  \n",
              " 351416   3.0   0.0          0     0  \n",
              " 918599   1.0   0.0          0     1  \n",
              " 728046   1.0   1.0          1     0  \n",
              " 300121   1.0   1.0          0     1  \n",
              " 872503   1.0   1.0          1     1  \n",
              " ...      ...   ...        ...   ...  \n",
              " 435271   1.0   0.0          0     0  \n",
              " 435997   1.0   0.0          1     2  \n",
              " 678590   2.0   0.0          0     2  \n",
              " 207290   1.0   0.0          0     2  \n",
              " 668889   2.0   1.0          0     2  \n",
              " \n",
              " [196027 rows x 20 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## data loader 생성\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_data = []\n",
        "val_data = []\n",
        "\n",
        "for i in tqdm(range(len(train_df))):\n",
        "    x_tmp = torch.tensor(train_df.iloc[i].drop('혈압상태'))\n",
        "    y_tmp = train_df['혈압상태'][i]\n",
        "    train_data.append((x_tmp, y_tmp))\n",
        "    \n",
        "for i in tqdm(range(len(val_df))):\n",
        "    x_tmp = torch.tensor(val_df.iloc[i].drop('혈압상태'))\n",
        "    y_tmp = val_df['혈압상태'][i]\n",
        "    val_data.append((x_tmp, y_tmp))\n",
        "    \n",
        "train_data[:5], val_data[:5], len(train_data), len(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpI4pw1Yyunu",
        "outputId": "87f63400-220e-40cf-b3b3-f2e537bb2b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 784106/784106 [13:34<00:00, 962.72it/s]\n",
            "100%|██████████| 196027/196027 [03:19<00:00, 984.59it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(tensor([  1.0000,  11.0000, 165.0000,  55.0000,  75.1000,   1.2000,   1.2000,\n",
              "             1.0000,   1.0000,  81.0000,  15.8000,   1.0000,   0.8000,  38.0000,\n",
              "            26.0000, 136.0000,   3.0000,   1.0000,   1.0000], dtype=torch.float64),\n",
              "   0),\n",
              "  (tensor([  1.0000,   9.0000, 170.0000,  85.0000,  91.0000,   1.5000,   1.5000,\n",
              "             1.0000,   1.0000, 100.0000,  16.2000,   1.0000,   1.0000,  23.0000,\n",
              "            48.0000,  43.0000,   2.0000,   0.0000,   1.0000], dtype=torch.float64),\n",
              "   1),\n",
              "  (tensor([  2.0000,  10.0000, 155.0000,  55.0000,  83.3000,   0.7000,   0.7000,\n",
              "             1.0000,   1.0000,  94.0000,  12.8000,   2.0000,   0.7000,  27.0000,\n",
              "            28.0000,  13.0000,   1.0000,   0.0000,   0.0000], dtype=torch.float64),\n",
              "   2),\n",
              "  (tensor([  2.0000,   9.0000, 155.0000,  50.0000,  78.0000,   1.5000,   1.5000,\n",
              "             1.0000,   1.0000,  89.0000,  13.2000,   1.0000,   0.8000,  19.0000,\n",
              "            11.0000,   4.0000,   1.0000,   0.0000,   0.0000], dtype=torch.float64),\n",
              "   2),\n",
              "  (tensor([  2.0000,  14.0000, 160.0000,  65.0000,  74.0000,   0.8000,   0.4000,\n",
              "             1.0000,   1.0000, 105.0000,  12.9000,   1.0000,   0.7000,  18.0000,\n",
              "            19.0000,  24.0000,   1.0000,   0.0000,   0.0000], dtype=torch.float64),\n",
              "   1)],\n",
              " [(tensor([  1.0000,  13.0000, 170.0000,  60.0000,  78.0000,   0.8000,   0.8000,\n",
              "             1.0000,   1.0000, 105.0000,  13.9000,   1.0000,   1.0000,  15.0000,\n",
              "            11.0000,  19.0000,   3.0000,   0.0000,   0.0000], dtype=torch.float64),\n",
              "   0),\n",
              "  (tensor([  1.0000,  12.0000, 165.0000,  70.0000,  83.0000,   1.0000,   1.0000,\n",
              "             1.0000,   1.0000, 102.0000,  15.4000,   1.0000,   1.0000,  22.0000,\n",
              "            21.0000,  22.0000,   1.0000,   0.0000,   0.0000], dtype=torch.float64),\n",
              "   1),\n",
              "  (tensor([  2.0000,  12.0000, 150.0000,  65.0000,  94.0000,   0.5000,   0.4000,\n",
              "             1.0000,   1.0000, 110.0000,  13.9000,   1.0000,   0.6000,  26.0000,\n",
              "            16.0000,  42.0000,   1.0000,   1.0000,   1.0000], dtype=torch.float64),\n",
              "   0),\n",
              "  (tensor([  1.0000,  13.0000, 160.0000,  60.0000,  74.9000,   0.5000,   0.8000,\n",
              "             1.0000,   1.0000,  83.0000,  15.8000,   1.0000,   1.1000,  36.0000,\n",
              "            36.0000,  26.0000,   1.0000,   1.0000,   0.0000], dtype=torch.float64),\n",
              "   1),\n",
              "  (tensor([  2.0000,  13.0000, 155.0000,  60.0000,  85.0000,   0.7000,   0.8000,\n",
              "             1.0000,   1.0000, 101.0000,  14.0000,   1.0000,   0.6000,  21.0000,\n",
              "            13.0000,   8.0000,   1.0000,   1.0000,   1.0000], dtype=torch.float64),\n",
              "   1)],\n",
              " 784106,\n",
              " 196027)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음과 같은 하이퍼 파라미터를 시도했습니다.\n",
        "\n",
        "optimizer \n",
        "  - Adam\n",
        "  - AdamW (채택)\n",
        "  - SGD\n",
        "\n",
        "lr_scheduler\n",
        "  - StepLR (채택)\n",
        "  - MultiStepLR\n",
        "\n"
      ],
      "metadata": {
        "id": "MLYXhk-0EHXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataset = MyDataset(train_data)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = MyDataset(val_data)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), betas=(0.9, 0.999), lr=1e-4, weight_decay=1e-6, eps=1e-08)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
        "\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer, \n",
        "    step_size= 5, \n",
        "    gamma=0.1\n",
        ")\n",
        "\n",
        "# lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "#     optimizer, \n",
        "#     milestones=[20,40], \n",
        "#     gamma=0.1\n",
        "# )\n",
        "\n"
      ],
      "metadata": {
        "id": "_o3ChukNdNuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    acc = correct / total\n",
        "    return acc"
      ],
      "metadata": {
        "id": "lqm03g64eqRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZUDKDtYe_Zz",
        "outputId": "f03a6e20-f0c1-4c46-8f15-58bbae4815d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNN(\n",
              "  (fc1): Linear(in_features=19, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 시작\n",
        "\n",
        "from time import time\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    print(\"epoch_step ==>\", epoch+1)\n",
        "    epoch_start = time()\n",
        "    \n",
        "    train_acc = 0\n",
        "    num_train_batches = 0\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input, b_labels = batch\n",
        "        \n",
        "        input = b_input.to(dtype=torch.float32)\n",
        "        labels = b_labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()  # 그라디언트 초기화\n",
        "        \n",
        "        logits = model(input)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        \n",
        "        train_acc += accuracy(logits, labels)\n",
        "        num_train_batches += 1\n",
        "        \n",
        "        \n",
        "        if step % 1000 == 0:\n",
        "            print(\"step :\", step, \"/\", len(train_loader), \"      loss :\", loss.item())\n",
        "        \n",
        "        loss.backward()  # 역전파\n",
        "        optimizer.step()  # 파라미터 업데이트\n",
        "        \n",
        "    lr_scheduler.step()  # 학습률 감소\n",
        "    print(\"lr: \", optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    val_acc = 0\n",
        "    num_val_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for val_batch in val_loader:\n",
        "            \n",
        "            val_batch = tuple(t.to(device) for t in val_batch)\n",
        "            val_input, val_labels = val_batch\n",
        "        \n",
        "            input = val_input.to(dtype=torch.float32)\n",
        "            labels = val_labels.to(device)\n",
        "            \n",
        "            logits = model(input)\n",
        "            val_acc += accuracy(logits, labels)\n",
        "            num_val_batches += 1\n",
        "        \n",
        "    train_acc /= num_train_batches\n",
        "    val_acc /= num_val_batches\n",
        "    \n",
        "    print(f'\\nEpoch {epoch+1}: Train Acc = {train_acc:.2f}, Val Acc = {val_acc:.2f}')\n",
        "    epoch_end = time()\n",
        "    \n",
        "    epoch_elapsed = epoch_end - epoch_start\n",
        "    print('Elapsed time is %f seconds.' % epoch_elapsed, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOD7-IT7CutD",
        "outputId": "0ba2cad8-0e4f-4616-e4ad-c6dd17003914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_step ==> 1\n",
            "step : 0 / 6126       loss : 4.77826452255249\n",
            "step : 1000 / 6126       loss : 1.0904873609542847\n",
            "step : 2000 / 6126       loss : 1.0632644891738892\n",
            "step : 3000 / 6126       loss : 1.0517127513885498\n",
            "step : 4000 / 6126       loss : 1.0394359827041626\n",
            "step : 5000 / 6126       loss : 1.0095802545547485\n",
            "step : 6000 / 6126       loss : 1.010966181755066\n",
            "lr:  0.0001\n",
            "\n",
            "Epoch 1: Train Acc = 0.46, Val Acc = 0.49\n",
            "Elapsed time is 16.956844 seconds. \n",
            "\n",
            "epoch_step ==> 2\n",
            "step : 0 / 6126       loss : 1.0452593564987183\n",
            "step : 1000 / 6126       loss : 1.0397653579711914\n",
            "step : 2000 / 6126       loss : 1.0580270290374756\n",
            "step : 3000 / 6126       loss : 1.0117261409759521\n",
            "step : 4000 / 6126       loss : 1.0977792739868164\n",
            "step : 5000 / 6126       loss : 1.0195575952529907\n",
            "step : 6000 / 6126       loss : 1.0315979719161987\n",
            "lr:  0.0001\n",
            "\n",
            "Epoch 2: Train Acc = 0.48, Val Acc = 0.49\n",
            "Elapsed time is 16.613703 seconds. \n",
            "\n",
            "epoch_step ==> 3\n",
            "step : 0 / 6126       loss : 1.0409446954727173\n",
            "step : 1000 / 6126       loss : 1.0711721181869507\n",
            "step : 2000 / 6126       loss : 0.9947773814201355\n",
            "step : 3000 / 6126       loss : 0.9996537566184998\n",
            "step : 4000 / 6126       loss : 0.9829259514808655\n",
            "step : 5000 / 6126       loss : 1.0252782106399536\n",
            "step : 6000 / 6126       loss : 1.045568823814392\n",
            "lr:  0.0001\n",
            "\n",
            "Epoch 3: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.555052 seconds. \n",
            "\n",
            "epoch_step ==> 4\n",
            "step : 0 / 6126       loss : 1.0168051719665527\n",
            "step : 1000 / 6126       loss : 1.0097237825393677\n",
            "step : 2000 / 6126       loss : 1.1090800762176514\n",
            "step : 3000 / 6126       loss : 1.0306479930877686\n",
            "step : 4000 / 6126       loss : 1.005173921585083\n",
            "step : 5000 / 6126       loss : 1.0053101778030396\n",
            "step : 6000 / 6126       loss : 1.0308061838150024\n",
            "lr:  0.0001\n",
            "\n",
            "Epoch 4: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.611231 seconds. \n",
            "\n",
            "epoch_step ==> 5\n",
            "step : 0 / 6126       loss : 1.0228177309036255\n",
            "step : 1000 / 6126       loss : 1.063686728477478\n",
            "step : 2000 / 6126       loss : 1.0463638305664062\n",
            "step : 3000 / 6126       loss : 1.029922604560852\n",
            "step : 4000 / 6126       loss : 1.0223307609558105\n",
            "step : 5000 / 6126       loss : 1.039784550666809\n",
            "step : 6000 / 6126       loss : 0.9859797954559326\n",
            "lr:  1e-05\n",
            "\n",
            "Epoch 5: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.386061 seconds. \n",
            "\n",
            "epoch_step ==> 6\n",
            "step : 0 / 6126       loss : 0.9690009355545044\n",
            "step : 1000 / 6126       loss : 1.0236626863479614\n",
            "step : 2000 / 6126       loss : 0.9764247536659241\n",
            "step : 3000 / 6126       loss : 1.0667122602462769\n",
            "step : 4000 / 6126       loss : 1.0239908695220947\n",
            "step : 5000 / 6126       loss : 0.9765253663063049\n",
            "step : 6000 / 6126       loss : 1.0699448585510254\n",
            "lr:  1e-05\n",
            "\n",
            "Epoch 6: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.448658 seconds. \n",
            "\n",
            "epoch_step ==> 7\n",
            "step : 0 / 6126       loss : 1.0342504978179932\n",
            "step : 1000 / 6126       loss : 1.002493977546692\n",
            "step : 2000 / 6126       loss : 1.1191837787628174\n",
            "step : 3000 / 6126       loss : 1.030810832977295\n",
            "step : 4000 / 6126       loss : 0.9871125817298889\n",
            "step : 5000 / 6126       loss : 1.0351611375808716\n",
            "step : 6000 / 6126       loss : 1.0286437273025513\n",
            "lr:  1e-05\n",
            "\n",
            "Epoch 7: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.829253 seconds. \n",
            "\n",
            "epoch_step ==> 8\n",
            "step : 0 / 6126       loss : 1.032952904701233\n",
            "step : 1000 / 6126       loss : 1.0426090955734253\n",
            "step : 2000 / 6126       loss : 1.0671473741531372\n",
            "step : 3000 / 6126       loss : 1.0069676637649536\n",
            "step : 4000 / 6126       loss : 0.961517333984375\n",
            "step : 5000 / 6126       loss : 1.097145438194275\n",
            "step : 6000 / 6126       loss : 1.0199395418167114\n",
            "lr:  1e-05\n",
            "\n",
            "Epoch 8: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.969049 seconds. \n",
            "\n",
            "epoch_step ==> 9\n",
            "step : 0 / 6126       loss : 0.9902774095535278\n",
            "step : 1000 / 6126       loss : 0.9742822051048279\n",
            "step : 2000 / 6126       loss : 0.9446768760681152\n",
            "step : 3000 / 6126       loss : 1.0199368000030518\n",
            "step : 4000 / 6126       loss : 1.0437337160110474\n",
            "step : 5000 / 6126       loss : 1.0602887868881226\n",
            "step : 6000 / 6126       loss : 1.082099437713623\n",
            "lr:  1e-05\n",
            "\n",
            "Epoch 9: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.372866 seconds. \n",
            "\n",
            "epoch_step ==> 10\n",
            "step : 0 / 6126       loss : 0.9781522750854492\n",
            "step : 1000 / 6126       loss : 1.0373643636703491\n",
            "step : 2000 / 6126       loss : 1.0654737949371338\n",
            "step : 3000 / 6126       loss : 0.9663718342781067\n",
            "step : 4000 / 6126       loss : 1.0587797164916992\n",
            "step : 5000 / 6126       loss : 1.0586755275726318\n",
            "step : 6000 / 6126       loss : 1.0029938220977783\n",
            "lr:  1.0000000000000002e-06\n",
            "\n",
            "Epoch 10: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.425489 seconds. \n",
            "\n",
            "epoch_step ==> 11\n",
            "step : 0 / 6126       loss : 1.0265790224075317\n",
            "step : 1000 / 6126       loss : 1.0136898756027222\n",
            "step : 2000 / 6126       loss : 1.0321111679077148\n",
            "step : 3000 / 6126       loss : 0.9995661973953247\n",
            "step : 4000 / 6126       loss : 1.0086323022842407\n",
            "step : 5000 / 6126       loss : 1.0258907079696655\n",
            "step : 6000 / 6126       loss : 1.039542555809021\n",
            "lr:  1.0000000000000002e-06\n",
            "\n",
            "Epoch 11: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.209587 seconds. \n",
            "\n",
            "epoch_step ==> 12\n",
            "step : 0 / 6126       loss : 1.0223495960235596\n",
            "step : 1000 / 6126       loss : 1.0000048875808716\n",
            "step : 2000 / 6126       loss : 0.976767361164093\n",
            "step : 3000 / 6126       loss : 0.9774318933486938\n",
            "step : 4000 / 6126       loss : 1.020737648010254\n",
            "step : 5000 / 6126       loss : 1.0328093767166138\n",
            "step : 6000 / 6126       loss : 0.9845549464225769\n",
            "lr:  1.0000000000000002e-06\n",
            "\n",
            "Epoch 12: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.437920 seconds. \n",
            "\n",
            "epoch_step ==> 13\n",
            "step : 0 / 6126       loss : 1.0218613147735596\n",
            "step : 1000 / 6126       loss : 1.0261236429214478\n",
            "step : 2000 / 6126       loss : 0.9924869537353516\n",
            "step : 3000 / 6126       loss : 1.115618348121643\n",
            "step : 4000 / 6126       loss : 1.0229065418243408\n",
            "step : 5000 / 6126       loss : 1.0694091320037842\n",
            "step : 6000 / 6126       loss : 1.0313482284545898\n",
            "lr:  1.0000000000000002e-06\n",
            "\n",
            "Epoch 13: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.641811 seconds. \n",
            "\n",
            "epoch_step ==> 14\n",
            "step : 0 / 6126       loss : 1.0392837524414062\n",
            "step : 1000 / 6126       loss : 1.0375456809997559\n",
            "step : 2000 / 6126       loss : 1.0119292736053467\n",
            "step : 3000 / 6126       loss : 0.9815176129341125\n",
            "step : 4000 / 6126       loss : 0.9647014141082764\n",
            "step : 5000 / 6126       loss : 0.9792768359184265\n",
            "step : 6000 / 6126       loss : 1.0404943227767944\n",
            "lr:  1.0000000000000002e-06\n",
            "\n",
            "Epoch 14: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.274945 seconds. \n",
            "\n",
            "epoch_step ==> 15\n",
            "step : 0 / 6126       loss : 0.9790480732917786\n",
            "step : 1000 / 6126       loss : 1.0126384496688843\n",
            "step : 2000 / 6126       loss : 0.9890007376670837\n",
            "step : 3000 / 6126       loss : 1.0590628385543823\n",
            "step : 4000 / 6126       loss : 0.9987451434135437\n",
            "step : 5000 / 6126       loss : 1.0229949951171875\n",
            "step : 6000 / 6126       loss : 1.0014461278915405\n",
            "lr:  1.0000000000000002e-07\n",
            "\n",
            "Epoch 15: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.251288 seconds. \n",
            "\n",
            "epoch_step ==> 16\n",
            "step : 0 / 6126       loss : 0.9652544260025024\n",
            "step : 1000 / 6126       loss : 0.982588529586792\n",
            "step : 2000 / 6126       loss : 1.0118470191955566\n",
            "step : 3000 / 6126       loss : 1.0112807750701904\n",
            "step : 4000 / 6126       loss : 1.0087029933929443\n",
            "step : 5000 / 6126       loss : 1.0352075099945068\n",
            "step : 6000 / 6126       loss : 1.0412068367004395\n",
            "lr:  1.0000000000000002e-07\n",
            "\n",
            "Epoch 16: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.361494 seconds. \n",
            "\n",
            "epoch_step ==> 17\n",
            "step : 0 / 6126       loss : 1.011860728263855\n",
            "step : 1000 / 6126       loss : 1.0441975593566895\n",
            "step : 2000 / 6126       loss : 1.0078414678573608\n",
            "step : 3000 / 6126       loss : 1.0126261711120605\n",
            "step : 4000 / 6126       loss : 1.0022282600402832\n",
            "step : 5000 / 6126       loss : 0.9915434718132019\n",
            "step : 6000 / 6126       loss : 1.0683698654174805\n",
            "lr:  1.0000000000000002e-07\n",
            "\n",
            "Epoch 17: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.527993 seconds. \n",
            "\n",
            "epoch_step ==> 18\n",
            "step : 0 / 6126       loss : 0.9819170832633972\n",
            "step : 1000 / 6126       loss : 1.0410844087600708\n",
            "step : 2000 / 6126       loss : 1.0129835605621338\n",
            "step : 3000 / 6126       loss : 1.0310136079788208\n",
            "step : 4000 / 6126       loss : 1.0563510656356812\n",
            "step : 5000 / 6126       loss : 1.0161418914794922\n",
            "step : 6000 / 6126       loss : 1.0363566875457764\n",
            "lr:  1.0000000000000002e-07\n",
            "\n",
            "Epoch 18: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.785572 seconds. \n",
            "\n",
            "epoch_step ==> 19\n",
            "step : 0 / 6126       loss : 0.9708213210105896\n",
            "step : 1000 / 6126       loss : 1.0086411237716675\n",
            "step : 2000 / 6126       loss : 1.0327303409576416\n",
            "step : 3000 / 6126       loss : 1.0158494710922241\n",
            "step : 4000 / 6126       loss : 1.0196442604064941\n",
            "step : 5000 / 6126       loss : 0.9847773909568787\n",
            "step : 6000 / 6126       loss : 1.0440850257873535\n",
            "lr:  1.0000000000000002e-07\n",
            "\n",
            "Epoch 19: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.886794 seconds. \n",
            "\n",
            "epoch_step ==> 20\n",
            "step : 0 / 6126       loss : 1.0420663356781006\n",
            "step : 1000 / 6126       loss : 0.9553758502006531\n",
            "step : 2000 / 6126       loss : 0.9949262142181396\n",
            "step : 3000 / 6126       loss : 1.0047566890716553\n",
            "step : 4000 / 6126       loss : 1.0769801139831543\n",
            "step : 5000 / 6126       loss : 0.9967086911201477\n",
            "step : 6000 / 6126       loss : 1.0534785985946655\n",
            "lr:  1.0000000000000004e-08\n",
            "\n",
            "Epoch 20: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.412321 seconds. \n",
            "\n",
            "epoch_step ==> 21\n",
            "step : 0 / 6126       loss : 1.0377436876296997\n",
            "step : 1000 / 6126       loss : 1.0014050006866455\n",
            "step : 2000 / 6126       loss : 1.0234904289245605\n",
            "step : 3000 / 6126       loss : 0.9844021797180176\n",
            "step : 4000 / 6126       loss : 1.0011759996414185\n",
            "step : 5000 / 6126       loss : 0.9847562313079834\n",
            "step : 6000 / 6126       loss : 1.000120759010315\n",
            "lr:  1.0000000000000004e-08\n",
            "\n",
            "Epoch 21: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.407082 seconds. \n",
            "\n",
            "epoch_step ==> 22\n",
            "step : 0 / 6126       loss : 1.0492327213287354\n",
            "step : 1000 / 6126       loss : 1.071398377418518\n",
            "step : 2000 / 6126       loss : 1.045841097831726\n",
            "step : 3000 / 6126       loss : 1.0104583501815796\n",
            "step : 4000 / 6126       loss : 1.0470694303512573\n",
            "step : 5000 / 6126       loss : 1.013389229774475\n",
            "step : 6000 / 6126       loss : 1.0019181966781616\n",
            "lr:  1.0000000000000004e-08\n",
            "\n",
            "Epoch 22: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.073082 seconds. \n",
            "\n",
            "epoch_step ==> 23\n",
            "step : 0 / 6126       loss : 1.0446257591247559\n",
            "step : 1000 / 6126       loss : 1.0450825691223145\n",
            "step : 2000 / 6126       loss : 1.0578974485397339\n",
            "step : 3000 / 6126       loss : 0.9334864020347595\n",
            "step : 4000 / 6126       loss : 1.0442132949829102\n",
            "step : 5000 / 6126       loss : 0.9731998443603516\n",
            "step : 6000 / 6126       loss : 1.0469940900802612\n",
            "lr:  1.0000000000000004e-08\n",
            "\n",
            "Epoch 23: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.777978 seconds. \n",
            "\n",
            "epoch_step ==> 24\n",
            "step : 0 / 6126       loss : 1.0815391540527344\n",
            "step : 1000 / 6126       loss : 1.0868335962295532\n",
            "step : 2000 / 6126       loss : 0.996149480342865\n",
            "step : 3000 / 6126       loss : 0.9920796155929565\n",
            "step : 4000 / 6126       loss : 0.981499969959259\n",
            "step : 5000 / 6126       loss : 1.0600383281707764\n",
            "step : 6000 / 6126       loss : 1.0540834665298462\n",
            "lr:  1.0000000000000004e-08\n",
            "\n",
            "Epoch 24: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.417704 seconds. \n",
            "\n",
            "epoch_step ==> 25\n",
            "step : 0 / 6126       loss : 0.955968976020813\n",
            "step : 1000 / 6126       loss : 0.9561291933059692\n",
            "step : 2000 / 6126       loss : 0.9991621971130371\n",
            "step : 3000 / 6126       loss : 1.0612061023712158\n",
            "step : 4000 / 6126       loss : 1.0021780729293823\n",
            "step : 5000 / 6126       loss : 0.9659278988838196\n",
            "step : 6000 / 6126       loss : 0.9885509014129639\n",
            "lr:  1.0000000000000005e-09\n",
            "\n",
            "Epoch 25: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.400707 seconds. \n",
            "\n",
            "epoch_step ==> 26\n",
            "step : 0 / 6126       loss : 1.0097473859786987\n",
            "step : 1000 / 6126       loss : 1.0589491128921509\n",
            "step : 2000 / 6126       loss : 1.0304666757583618\n",
            "step : 3000 / 6126       loss : 1.0872986316680908\n",
            "step : 4000 / 6126       loss : 1.034335970878601\n",
            "step : 5000 / 6126       loss : 0.9834824204444885\n",
            "step : 6000 / 6126       loss : 1.0138392448425293\n",
            "lr:  1.0000000000000005e-09\n",
            "\n",
            "Epoch 26: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.237228 seconds. \n",
            "\n",
            "epoch_step ==> 27\n",
            "step : 0 / 6126       loss : 1.069737434387207\n",
            "step : 1000 / 6126       loss : 1.0385934114456177\n",
            "step : 2000 / 6126       loss : 1.0598969459533691\n",
            "step : 3000 / 6126       loss : 1.0525758266448975\n",
            "step : 4000 / 6126       loss : 1.0316442251205444\n",
            "step : 5000 / 6126       loss : 1.0019067525863647\n",
            "step : 6000 / 6126       loss : 1.0149810314178467\n",
            "lr:  1.0000000000000005e-09\n",
            "\n",
            "Epoch 27: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.430525 seconds. \n",
            "\n",
            "epoch_step ==> 28\n",
            "step : 0 / 6126       loss : 0.9443647265434265\n",
            "step : 1000 / 6126       loss : 0.9741833209991455\n",
            "step : 2000 / 6126       loss : 1.0383338928222656\n",
            "step : 3000 / 6126       loss : 1.0075595378875732\n",
            "step : 4000 / 6126       loss : 0.9480430483818054\n",
            "step : 5000 / 6126       loss : 1.0166622400283813\n",
            "step : 6000 / 6126       loss : 0.9901958703994751\n",
            "lr:  1.0000000000000005e-09\n",
            "\n",
            "Epoch 28: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.477662 seconds. \n",
            "\n",
            "epoch_step ==> 29\n",
            "step : 0 / 6126       loss : 1.0056078433990479\n",
            "step : 1000 / 6126       loss : 1.045700192451477\n",
            "step : 2000 / 6126       loss : 1.067042589187622\n",
            "step : 3000 / 6126       loss : 1.0146547555923462\n",
            "step : 4000 / 6126       loss : 0.9900081157684326\n",
            "step : 5000 / 6126       loss : 0.9974185228347778\n",
            "step : 6000 / 6126       loss : 1.0007281303405762\n",
            "lr:  1.0000000000000005e-09\n",
            "\n",
            "Epoch 29: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.501054 seconds. \n",
            "\n",
            "epoch_step ==> 30\n",
            "step : 0 / 6126       loss : 0.9942647814750671\n",
            "step : 1000 / 6126       loss : 1.077687382698059\n",
            "step : 2000 / 6126       loss : 1.0228636264801025\n",
            "step : 3000 / 6126       loss : 0.9557459950447083\n",
            "step : 4000 / 6126       loss : 1.0160497426986694\n",
            "step : 5000 / 6126       loss : 0.9983537197113037\n",
            "step : 6000 / 6126       loss : 1.059178352355957\n",
            "lr:  1.0000000000000006e-10\n",
            "\n",
            "Epoch 30: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 19.185781 seconds. \n",
            "\n",
            "epoch_step ==> 31\n",
            "step : 0 / 6126       loss : 1.0052787065505981\n",
            "step : 1000 / 6126       loss : 1.0365850925445557\n",
            "step : 2000 / 6126       loss : 1.0305910110473633\n",
            "step : 3000 / 6126       loss : 1.0262089967727661\n",
            "step : 4000 / 6126       loss : 0.9917237162590027\n",
            "step : 5000 / 6126       loss : 0.9553930759429932\n",
            "step : 6000 / 6126       loss : 0.9743189811706543\n",
            "lr:  1.0000000000000006e-10\n",
            "\n",
            "Epoch 31: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 23.041401 seconds. \n",
            "\n",
            "epoch_step ==> 32\n",
            "step : 0 / 6126       loss : 1.0080662965774536\n",
            "step : 1000 / 6126       loss : 1.0544475317001343\n",
            "step : 2000 / 6126       loss : 1.0613499879837036\n",
            "step : 3000 / 6126       loss : 0.9984583854675293\n",
            "step : 4000 / 6126       loss : 1.0190160274505615\n",
            "step : 5000 / 6126       loss : 1.0510483980178833\n",
            "step : 6000 / 6126       loss : 1.011804461479187\n",
            "lr:  1.0000000000000006e-10\n",
            "\n",
            "Epoch 32: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 21.900190 seconds. \n",
            "\n",
            "epoch_step ==> 33\n",
            "step : 0 / 6126       loss : 1.0331439971923828\n",
            "step : 1000 / 6126       loss : 1.0042401552200317\n",
            "step : 2000 / 6126       loss : 1.0148797035217285\n",
            "step : 3000 / 6126       loss : 0.9790205955505371\n",
            "step : 4000 / 6126       loss : 0.9844307899475098\n",
            "step : 5000 / 6126       loss : 1.0292648077011108\n",
            "step : 6000 / 6126       loss : 1.020970106124878\n",
            "lr:  1.0000000000000006e-10\n",
            "\n",
            "Epoch 33: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 25.059307 seconds. \n",
            "\n",
            "epoch_step ==> 34\n",
            "step : 0 / 6126       loss : 1.0209673643112183\n",
            "step : 1000 / 6126       loss : 1.0714232921600342\n",
            "step : 2000 / 6126       loss : 1.0133416652679443\n",
            "step : 3000 / 6126       loss : 0.9554870128631592\n",
            "step : 4000 / 6126       loss : 1.004730463027954\n",
            "step : 5000 / 6126       loss : 1.017342448234558\n",
            "step : 6000 / 6126       loss : 1.029656171798706\n",
            "lr:  1.0000000000000006e-10\n",
            "\n",
            "Epoch 34: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 23.760660 seconds. \n",
            "\n",
            "epoch_step ==> 35\n",
            "step : 0 / 6126       loss : 1.0350385904312134\n",
            "step : 1000 / 6126       loss : 1.0247491598129272\n",
            "step : 2000 / 6126       loss : 1.0305943489074707\n",
            "step : 3000 / 6126       loss : 1.0444631576538086\n",
            "step : 4000 / 6126       loss : 1.0347614288330078\n",
            "step : 5000 / 6126       loss : 0.9931684136390686\n",
            "step : 6000 / 6126       loss : 1.0573581457138062\n",
            "lr:  1.0000000000000006e-11\n",
            "\n",
            "Epoch 35: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 18.968424 seconds. \n",
            "\n",
            "epoch_step ==> 36\n",
            "step : 0 / 6126       loss : 0.9805412888526917\n",
            "step : 1000 / 6126       loss : 1.019970417022705\n",
            "step : 2000 / 6126       loss : 1.0345745086669922\n",
            "step : 3000 / 6126       loss : 0.9642626047134399\n",
            "step : 4000 / 6126       loss : 1.0439260005950928\n",
            "step : 5000 / 6126       loss : 0.9894161224365234\n",
            "step : 6000 / 6126       loss : 1.0690717697143555\n",
            "lr:  1.0000000000000006e-11\n",
            "\n",
            "Epoch 36: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 18.342662 seconds. \n",
            "\n",
            "epoch_step ==> 37\n",
            "step : 0 / 6126       loss : 1.0970220565795898\n",
            "step : 1000 / 6126       loss : 1.0871617794036865\n",
            "step : 2000 / 6126       loss : 1.0309250354766846\n",
            "step : 3000 / 6126       loss : 1.0318994522094727\n",
            "step : 4000 / 6126       loss : 1.048602819442749\n",
            "step : 5000 / 6126       loss : 1.0868011713027954\n",
            "step : 6000 / 6126       loss : 1.0356148481369019\n",
            "lr:  1.0000000000000006e-11\n",
            "\n",
            "Epoch 37: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.158812 seconds. \n",
            "\n",
            "epoch_step ==> 38\n",
            "step : 0 / 6126       loss : 1.1184210777282715\n",
            "step : 1000 / 6126       loss : 0.961727499961853\n",
            "step : 2000 / 6126       loss : 1.0220530033111572\n",
            "step : 3000 / 6126       loss : 1.0557501316070557\n",
            "step : 4000 / 6126       loss : 1.054006814956665\n",
            "step : 5000 / 6126       loss : 1.0197808742523193\n",
            "step : 6000 / 6126       loss : 0.9892188310623169\n",
            "lr:  1.0000000000000006e-11\n",
            "\n",
            "Epoch 38: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 21.691123 seconds. \n",
            "\n",
            "epoch_step ==> 39\n",
            "step : 0 / 6126       loss : 0.9964485168457031\n",
            "step : 1000 / 6126       loss : 1.0193151235580444\n",
            "step : 2000 / 6126       loss : 1.0136387348175049\n",
            "step : 3000 / 6126       loss : 1.0135586261749268\n",
            "step : 4000 / 6126       loss : 0.9743949770927429\n",
            "step : 5000 / 6126       loss : 0.9962272644042969\n",
            "step : 6000 / 6126       loss : 0.9479524493217468\n",
            "lr:  1.0000000000000006e-11\n",
            "\n",
            "Epoch 39: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 19.636415 seconds. \n",
            "\n",
            "epoch_step ==> 40\n",
            "step : 0 / 6126       loss : 1.0594556331634521\n",
            "step : 1000 / 6126       loss : 0.9485909938812256\n",
            "step : 2000 / 6126       loss : 0.9647514224052429\n",
            "step : 3000 / 6126       loss : 0.987053632736206\n",
            "step : 4000 / 6126       loss : 0.9777544140815735\n",
            "step : 5000 / 6126       loss : 0.9781466722488403\n",
            "step : 6000 / 6126       loss : 1.0310182571411133\n",
            "lr:  1.0000000000000006e-12\n",
            "\n",
            "Epoch 40: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 21.228063 seconds. \n",
            "\n",
            "epoch_step ==> 41\n",
            "step : 0 / 6126       loss : 0.9868462681770325\n",
            "step : 1000 / 6126       loss : 0.998644232749939\n",
            "step : 2000 / 6126       loss : 1.0230158567428589\n",
            "step : 3000 / 6126       loss : 0.9983689188957214\n",
            "step : 4000 / 6126       loss : 0.9722208976745605\n",
            "step : 5000 / 6126       loss : 1.0098668336868286\n",
            "step : 6000 / 6126       loss : 1.005092978477478\n",
            "lr:  1.0000000000000006e-12\n",
            "\n",
            "Epoch 41: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.865350 seconds. \n",
            "\n",
            "epoch_step ==> 42\n",
            "step : 0 / 6126       loss : 0.9827972054481506\n",
            "step : 1000 / 6126       loss : 1.077300786972046\n",
            "step : 2000 / 6126       loss : 1.0128130912780762\n",
            "step : 3000 / 6126       loss : 1.0006718635559082\n",
            "step : 4000 / 6126       loss : 0.9735587239265442\n",
            "step : 5000 / 6126       loss : 1.0008900165557861\n",
            "step : 6000 / 6126       loss : 0.9977951049804688\n",
            "lr:  1.0000000000000006e-12\n",
            "\n",
            "Epoch 42: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 22.451895 seconds. \n",
            "\n",
            "epoch_step ==> 43\n",
            "step : 0 / 6126       loss : 0.9896465539932251\n",
            "step : 1000 / 6126       loss : 1.0184319019317627\n",
            "step : 2000 / 6126       loss : 1.0330619812011719\n",
            "step : 3000 / 6126       loss : 1.0572805404663086\n",
            "step : 4000 / 6126       loss : 1.0241308212280273\n",
            "step : 5000 / 6126       loss : 1.0393574237823486\n",
            "step : 6000 / 6126       loss : 1.0149599313735962\n",
            "lr:  1.0000000000000006e-12\n",
            "\n",
            "Epoch 43: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.262657 seconds. \n",
            "\n",
            "epoch_step ==> 44\n",
            "step : 0 / 6126       loss : 0.9300976395606995\n",
            "step : 1000 / 6126       loss : 0.9941078424453735\n",
            "step : 2000 / 6126       loss : 0.9896574020385742\n",
            "step : 3000 / 6126       loss : 1.0240119695663452\n",
            "step : 4000 / 6126       loss : 1.003066897392273\n",
            "step : 5000 / 6126       loss : 1.0566346645355225\n",
            "step : 6000 / 6126       loss : 1.0001071691513062\n",
            "lr:  1.0000000000000006e-12\n",
            "\n",
            "Epoch 44: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 18.128469 seconds. \n",
            "\n",
            "epoch_step ==> 45\n",
            "step : 0 / 6126       loss : 1.026322841644287\n",
            "step : 1000 / 6126       loss : 0.9976065754890442\n",
            "step : 2000 / 6126       loss : 1.0748323202133179\n",
            "step : 3000 / 6126       loss : 0.9946573376655579\n",
            "step : 4000 / 6126       loss : 1.0391308069229126\n",
            "step : 5000 / 6126       loss : 1.051935076713562\n",
            "step : 6000 / 6126       loss : 1.035562515258789\n",
            "lr:  1.0000000000000007e-13\n",
            "\n",
            "Epoch 45: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 22.915750 seconds. \n",
            "\n",
            "epoch_step ==> 46\n",
            "step : 0 / 6126       loss : 1.0263488292694092\n",
            "step : 1000 / 6126       loss : 1.0076930522918701\n",
            "step : 2000 / 6126       loss : 1.0074734687805176\n",
            "step : 3000 / 6126       loss : 0.994358479976654\n",
            "step : 4000 / 6126       loss : 1.0442249774932861\n",
            "step : 5000 / 6126       loss : 1.056552767753601\n",
            "step : 6000 / 6126       loss : 1.040170431137085\n",
            "lr:  1.0000000000000007e-13\n",
            "\n",
            "Epoch 46: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.361882 seconds. \n",
            "\n",
            "epoch_step ==> 47\n",
            "step : 0 / 6126       loss : 1.067520022392273\n",
            "step : 1000 / 6126       loss : 1.0390721559524536\n",
            "step : 2000 / 6126       loss : 0.9692209362983704\n",
            "step : 3000 / 6126       loss : 1.0491232872009277\n",
            "step : 4000 / 6126       loss : 1.0006850957870483\n",
            "step : 5000 / 6126       loss : 1.012573003768921\n",
            "step : 6000 / 6126       loss : 1.077933430671692\n",
            "lr:  1.0000000000000007e-13\n",
            "\n",
            "Epoch 47: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 18.668267 seconds. \n",
            "\n",
            "epoch_step ==> 48\n",
            "step : 0 / 6126       loss : 1.0443909168243408\n",
            "step : 1000 / 6126       loss : 0.9657583236694336\n",
            "step : 2000 / 6126       loss : 1.060197353363037\n",
            "step : 3000 / 6126       loss : 1.0128370523452759\n",
            "step : 4000 / 6126       loss : 1.0221540927886963\n",
            "step : 5000 / 6126       loss : 0.9962902665138245\n",
            "step : 6000 / 6126       loss : 0.9898223876953125\n",
            "lr:  1.0000000000000007e-13\n",
            "\n",
            "Epoch 48: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.580838 seconds. \n",
            "\n",
            "epoch_step ==> 49\n",
            "step : 0 / 6126       loss : 1.1145061254501343\n",
            "step : 1000 / 6126       loss : 1.0062140226364136\n",
            "step : 2000 / 6126       loss : 0.9875423908233643\n",
            "step : 3000 / 6126       loss : 0.9838690161705017\n",
            "step : 4000 / 6126       loss : 1.0317354202270508\n",
            "step : 5000 / 6126       loss : 0.9758463501930237\n",
            "step : 6000 / 6126       loss : 0.9699898362159729\n",
            "lr:  1.0000000000000007e-13\n",
            "\n",
            "Epoch 49: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 16.510603 seconds. \n",
            "\n",
            "epoch_step ==> 50\n",
            "step : 0 / 6126       loss : 1.032779335975647\n",
            "step : 1000 / 6126       loss : 1.0230183601379395\n",
            "step : 2000 / 6126       loss : 1.0017297267913818\n",
            "step : 3000 / 6126       loss : 1.0116366147994995\n",
            "step : 4000 / 6126       loss : 1.0722380876541138\n",
            "step : 5000 / 6126       loss : 0.9718736410140991\n",
            "step : 6000 / 6126       loss : 1.0032799243927002\n",
            "lr:  1.0000000000000008e-14\n",
            "\n",
            "Epoch 50: Train Acc = 0.49, Val Acc = 0.50\n",
            "Elapsed time is 17.304069 seconds. \n",
            "\n"
          ]
        }
      ]
    }
  ]
}